/**
 * å¢å¼ºçš„æ–‡å­—ç”ŸæˆæœåŠ¡
 * æ”¯æŒå¤šç§AIæœåŠ¡å•†çš„ç»Ÿä¸€æ¥å£
 */

import type { 
  ApiConfig, 
  TextApiProvider
} from '../types';

/**
 * è·å–æœåŠ¡å•†æ˜¾ç¤ºåç§°
 */
export function getProviderDisplayName(provider: TextApiProvider): string {
  const names: Record<TextApiProvider, string> = {
    gemini: 'Google Gemini',
    openai: 'OpenAI GPT',
    claude: 'Anthropic Claude',
    deepseek: 'DeepSeek API',
    siliconflow: 'SiliconFlow',
    azure_openai: 'Azure OpenAI',
    wenxin: 'ç™¾åº¦æ–‡å¿ƒä¸€è¨€',
    tongyi: 'é˜¿é‡Œé€šä¹‰åƒé—®',
    hunyuan: 'è…¾è®¯æ··å…ƒ',
    doubao: 'å­—èŠ‚è±†åŒ…',
    qwen: 'é˜¿é‡Œåƒé—®',
    yi: 'é›¶ä¸€ä¸‡ç‰©',
    moonshot: 'æœˆä¹‹æš—é¢ Kimi',
    zhipu: 'æ™ºè°± GLM',
    minimax: 'MiniMax',
    baichuan: 'ç™¾å·æ™ºèƒ½',
    builtin_free: 'å†…ç½®å…è´¹æœåŠ¡'
  };
  return names[provider] || provider;
}

/**
 * æ£€æŸ¥æœåŠ¡å•†æ˜¯å¦å¯ç”¨
 */
export function isProviderAvailable(provider: TextApiProvider): boolean {
  const availableProviders: TextApiProvider[] = [
    'gemini',
    'openai',
    'claude', 
    'deepseek', 
    'siliconflow',
    'hunyuan',
    'azure_openai',
    'wenxin',
    'tongyi',
    'doubao',
    'qwen',
    'yi',
    'moonshot',
    'zhipu',
    'minimax',
    'baichuan',
    'builtin_free'
  ];
  return availableProviders.includes(provider);
}

/**
 * ä½¿ç”¨æŒ‡å®šçš„æ–‡æœ¬ç”ŸæˆæœåŠ¡
 */
export async function generateTextWithProvider(
  provider: TextApiProvider, 
  prompt: string, 
  apiKey: string,
  options: {
    customEndpoint?: string;
    model?: string;
    temperature?: number;
    maxTokens?: number;
  } = {}
): Promise<string> {
  console.log(`ğŸ”„ ä½¿ç”¨${getProviderDisplayName(provider)}ç”Ÿæˆæ–‡æœ¬...`);
  
  try {
    switch (provider) {
      case 'deepseek': {
        const deepseekService = await import('./deepseekService');
        return await deepseekService.generateTextWithDeepSeek(prompt, apiKey, {
          baseURL: options.customEndpoint,
          model: options.model,
          temperature: options.temperature,
          maxTokens: options.maxTokens
        });
      }
      
      case 'siliconflow': {
        const siliconflowService = await import('./siliconflowService');
        return await siliconflowService.generateTextWithSiliconFlow(prompt, apiKey, {
          baseURL: options.customEndpoint,
          model: options.model,
          temperature: options.temperature,
          maxTokens: options.maxTokens
        });
      }
      
      case 'openai': {
        const openaiService = await import('./openaiService');
        return await openaiService.generateTextWithOpenAI(prompt, apiKey, {
          baseURL: options.customEndpoint,
          model: options.model,
          temperature: options.temperature,
          maxTokens: options.maxTokens
        });
      }
      
      case 'claude': {
        const claudeService = await import('./claudeService');
        return await claudeService.generateTextWithClaude(prompt, apiKey, {
          baseURL: options.customEndpoint,
          model: options.model,
          temperature: options.temperature,
          maxTokens: options.maxTokens
        });
      }
      
      case 'gemini': {
        // ä½¿ç”¨ç°æœ‰çš„GeminiæœåŠ¡
        const { generateTravelScenario } = await import('./geminiService');
        const response = await generateTravelScenario('é€šç”¨', '1å¤©', 'ç”¨æˆ·', prompt);
        return response.destinationName + '\n' + response.coreScenes.map(s => s.description).join('\n');
      }
      
      case 'hunyuan': {
        // ä½¿ç”¨è…¾è®¯æ··å…ƒæœåŠ¡
        const { callTencentHunyuanAPI } = await import('./tencentHunyuanService');
        const messages = [{ role: 'user' as const, content: prompt }];
        return await callTencentHunyuanAPI(messages, options.model || 'hunyuan-turbo');
      }
      
      case 'builtin_free': {
        return `[å†…ç½®æ¨¡æ‹Ÿå›å¤] åŸºäºæç¤ºè¯"${prompt.substring(0, 50)}..."ç”Ÿæˆçš„å†…å®¹ã€‚è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿå›å¤ï¼Œå®é™…ä½¿ç”¨æ—¶ä¼šæ ¹æ®å…·ä½“åœºæ™¯ç”Ÿæˆç›¸åº”å†…å®¹ã€‚`;
      }
      
      case 'azure_openai':
      case 'wenxin':
      case 'tongyi':
      case 'doubao':
      case 'qwen':
      case 'yi':
      case 'moonshot':
      case 'zhipu':
      case 'minimax':
      case 'baichuan':
        // è¿™äº›æœåŠ¡å•†ä½¿ç”¨é€šç”¨çš„OpenAIå…¼å®¹æ¥å£
        return await generateWithOpenAICompatible(provider, prompt, apiKey, options);
        
      default:
        throw new Error(`ä¸æ”¯æŒçš„æœåŠ¡å•†: ${provider}`);
    }
  } catch (error) {
    console.error(`${getProviderDisplayName(provider)}æ–‡æœ¬ç”Ÿæˆå¤±è´¥:`, error);
    throw error;
  }
}

/**
 * ä½¿ç”¨OpenAIå…¼å®¹æ¥å£ç”Ÿæˆæ–‡æœ¬
 */
async function generateWithOpenAICompatible(
  provider: TextApiProvider,
  prompt: string,
  apiKey: string,
  options: {
    customEndpoint?: string;
    model?: string;
    temperature?: number;
    maxTokens?: number;
  } = {}
): Promise<string> {
  // è·å–é»˜è®¤ç«¯ç‚¹å’Œæ¨¡å‹é…ç½®
  const providerConfig = getProviderConfig(provider);
  const baseURL = options.customEndpoint || providerConfig.defaultEndpoint;
  const model = options.model || providerConfig.defaultModel;

  const requestBody = {
    model: model,
    messages: [
      {
        role: 'user',
        content: prompt
      }
    ],
    temperature: options.temperature || 0.7,
    max_tokens: options.maxTokens || 4000
  };

  try {
    const response = await fetch(`${baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
        'User-Agent': 'travel-generator/1.0'
      },
      body: JSON.stringify(requestBody)
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`${getProviderDisplayName(provider)} APIè°ƒç”¨å¤±è´¥ (${response.status}): ${errorText}`);
    }

    const result = await response.json();
    
    if (!result.choices || result.choices.length === 0) {
      throw new Error(`${getProviderDisplayName(provider)} APIå“åº”æ ¼å¼é”™è¯¯`);
    }

    return result.choices[0].message.content.trim();
  } catch (error) {
    console.error(`${getProviderDisplayName(provider)} APIè°ƒç”¨å¤±è´¥:`, error);
    throw error;
  }
}

/**
 * è·å–æœåŠ¡å•†é…ç½®
 */
function getProviderConfig(provider: TextApiProvider): {
  defaultEndpoint: string;
  defaultModel: string;
} {
  const configs: Record<string, { defaultEndpoint: string; defaultModel: string }> = {
    azure_openai: {
      defaultEndpoint: 'https://your-resource.openai.azure.com',
      defaultModel: 'gpt-4o'
    },
    wenxin: {
      defaultEndpoint: 'https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop',
      defaultModel: 'ernie-4.0-turbo'
    },
    tongyi: {
      defaultEndpoint: 'https://dashscope.aliyuncs.com/api/v1',
      defaultModel: 'qwen2.5-72b-instruct'
    },
    doubao: {
      defaultEndpoint: 'https://ark.cn-beijing.volces.com/api/v3',
      defaultModel: 'doubao-pro-32k'
    },
    qwen: {
      defaultEndpoint: 'https://dashscope.aliyuncs.com/api/v1',
      defaultModel: 'qwen2.5-72b-instruct'
    },
    yi: {
      defaultEndpoint: 'https://api.lingyiwanwu.com/v1',
      defaultModel: 'yi-large'
    },
    moonshot: {
      defaultEndpoint: 'https://api.moonshot.cn/v1',
      defaultModel: 'moonshot-v1-128k'
    },
    zhipu: {
      defaultEndpoint: 'https://open.bigmodel.cn/api/paas/v4',
      defaultModel: 'glm-4-plus'
    },
    minimax: {
      defaultEndpoint: 'https://api.minimax.chat/v1',
      defaultModel: 'abab6.5s-chat'
    },
    baichuan: {
      defaultEndpoint: 'https://api.baichuan-ai.com/v1',
      defaultModel: 'baichuan4'
    },
    openai: {
      defaultEndpoint: 'https://api.openai.com/v1',
      defaultModel: 'gpt-4o'
    },
    claude: {
      defaultEndpoint: 'https://api.anthropic.com',
      defaultModel: 'claude-3-5-sonnet-20241022'
    },
    deepseek: {
      defaultEndpoint: 'https://api.deepseek.com/v1',
      defaultModel: 'deepseek-chat'
    },
    siliconflow: {
      defaultEndpoint: 'https://api.siliconflow.cn/v1',
      defaultModel: 'Qwen/Qwen2.5-72B-Instruct'
    },
    gemini: {
      defaultEndpoint: 'https://generativelanguage.googleapis.com/v1beta',
      defaultModel: 'gemini-2.0-flash-exp'
    },
    hunyuan: {
      defaultEndpoint: 'https://api.hunyuan.cloud.tencent.com/v1',
      defaultModel: 'hunyuan-pro'
    }
  };

  return configs[provider] || {
    defaultEndpoint: 'https://api.openai.com/v1',
    defaultModel: 'gpt-4o'
  };
}

/**
 * æµ‹è¯•æŒ‡å®šæœåŠ¡å•†çš„è¿æ¥
 */
export async function testProviderConnection(
  provider: TextApiProvider,
  apiKey: string,
  options: {
    customEndpoint?: string;
    model?: string;
  } = {}
): Promise<{ success: boolean; message: string; details?: string }> {
  try {
    if (!isProviderAvailable(provider)) {
      return {
        success: false,
        message: `${getProviderDisplayName(provider)}æœåŠ¡æš‚æœªå®ç°`,
        details: 'è¯¥æœåŠ¡å•†æ­£åœ¨å¼€å‘ä¸­ï¼Œè¯·é€‰æ‹©å…¶ä»–å¯ç”¨çš„æœåŠ¡å•†'
      };
    }

    switch (provider) {
      case 'deepseek': {
        const deepseekService = await import('./deepseekService');
        if (deepseekService) {
          return await deepseekService.testDeepSeekConnection(apiKey, options);
        }
        throw new Error('DeepSeekæœåŠ¡æ¨¡å—ä¸å¯ç”¨');
      }
      
      case 'siliconflow': {
        const siliconflowService = await import('./siliconflowService');
        if (siliconflowService) {
          return await siliconflowService.testSiliconFlowConnection(apiKey, options);
        }
        throw new Error('SiliconFlowæœåŠ¡æ¨¡å—ä¸å¯ç”¨');
      }
      
      case 'openai': {
        const openaiService = await import('./openaiService');
        return await openaiService.testOpenAIConnection(apiKey, options);
      }
      
      case 'claude': {
        const claudeService = await import('./claudeService');
        return await claudeService.testClaudeConnection(apiKey, options);
      }
      
      case 'gemini': {
        const testResponse = await generateTextWithProvider(provider, 'è¯·å›å¤"è¿æ¥æ­£å¸¸"', apiKey);
        return {
          success: true,
          message: 'Gemini APIè¿æ¥æˆåŠŸ',
          details: `å“åº”: ${testResponse.substring(0, 50)}...`
        };
      }
      
      case 'hunyuan': {
        // ä½¿ç”¨è…¾è®¯æ··å…ƒè¿æ¥æµ‹è¯•
        const { testTencentHunyuanConnection } = await import('./tencentHunyuanService');
        return await testTencentHunyuanConnection();
      }
      
      case 'builtin_free': {
        return {
          success: true,
          message: 'å†…ç½®å…è´¹æœåŠ¡å¯ç”¨',
          details: 'æ— éœ€APIå¯†é’¥ï¼Œç›´æ¥ä½¿ç”¨æ¨¡æ‹Ÿå†…å®¹'
        };
      }
      
      case 'azure_openai':
      case 'wenxin':
      case 'tongyi':
      case 'doubao':
      case 'qwen':
      case 'yi':
      case 'moonshot':
      case 'zhipu':
      case 'minimax':
      case 'baichuan': {
        // ä½¿ç”¨é€šç”¨æµ‹è¯•æ–¹æ³•
        try {
          const testResponse = await generateWithOpenAICompatible(
            provider, 
            'è¯·å›å¤"è¿æ¥æµ‹è¯•æˆåŠŸ"', 
            apiKey, 
            options
          );
          return {
            success: true,
            message: `${getProviderDisplayName(provider)} APIè¿æ¥æˆåŠŸ`,
            details: `å“åº”: ${testResponse.substring(0, 50)}...`
          };
        } catch (error: any) {
          return {
            success: false,
            message: `${getProviderDisplayName(provider)} APIè¿æ¥å¤±è´¥`,
            details: error.message
          };
        }
      }
      
      default:
        return {
          success: false,
          message: `${getProviderDisplayName(provider)}æœåŠ¡è¿æ¥æµ‹è¯•æš‚æœªå®ç°`,
          details: 'è¯·ç›´æ¥ä½¿ç”¨è¯¥æœåŠ¡æˆ–è”ç³»å¼€å‘è€…'
        };
    }
  } catch (error: any) {
    return {
      success: false,
      message: `${getProviderDisplayName(provider)}è¿æ¥æµ‹è¯•å¤±è´¥`,
      details: error.message
    };
  }
} 